{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Happy_House_Detection_Pytorch.ipynb",
      "provenance": [],
      "mount_file_id": "1mvL0Q_JbteQj3p5wbmCsHy92BWMjOq1h",
      "authorship_tag": "ABX9TyMf2nsnQyWDZKkr53owO77d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sftSalman/CNN/blob/main/Happy_House_Detection_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cqAiJsl7I3c9"
      },
      "outputs": [],
      "source": [
        "import h5py \n",
        "import numpy as np \n",
        "import torch \n",
        "import cv2 \n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import math \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import PIL \n",
        "#from scipy import indimage \n",
        "from scipy import ndimage\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(batch_size =64):\n",
        "  train_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/train_happy.h5','r')\n",
        "  x_train = np.array(train_dataset['train_set_x'][:])\n",
        "  x_train = np.transpose(x_train)\n",
        "  y_train = np.array(train_dataset['train_set_y'][:])\n",
        "  y_train = y_train.reshape((1,y_train.shape[0]).T\n",
        "                            \n",
        "  #test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/test_happy.h5','r')\n",
        "  #test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/datasets/test_signs.h5', 'r')\n",
        "  #test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/test_happy.h5', \"r\")\n",
        "  #h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/datasets/test_signs.h5', \"r\")\n",
        "  test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/test_happy.h5', \"r\")\n",
        "  x_test = np.array(test_dataset['test_set_x'][:])\n",
        "  x_test = np.transpose(test_dataset)\n",
        "  y_test = np.array(test_dataset['test_set_y'][:])\n",
        "  y_test = y_test.rehape((1,y_test.reshape[0])).T\n",
        "\n",
        "  classes = np.array(test_dataset['list_classes'][:])\n",
        "  X_train_tensor = torch.tensor(x_train,dtype=float)/255\n",
        "  Y_train_tensor = torch.tensor(y_train,dtype=long)\n",
        "\n",
        "  X_test_tensor = torch.tensor(x_test,dtype=float)/255\n",
        "  Y_test_tensor = torch.tensor(y_test,dtype=long)\n",
        "\n",
        "  train_dataset = TensorDataset(X_train_tensor,Y_train_tensor)\n",
        "  test-dataset = TensorDataset(X_test_tensor,Y_test_tensor)\n",
        "  train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
        "  return train_dataset,test_dataset,train_loader,test_loader ,classes\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "991ezeVtL18n",
        "outputId": "0886cd70-5e98-4967-a6c0-2590d0dc22ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-4fe0de4f6bfc>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/test_happy.h5', \"r\")\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(batch_size=64):\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/train_happy.h5', \"r\")\n",
        "    x_train = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    x_train = np.transpose(x_train)\n",
        "    y_train = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "    y_train = y_train.reshape((1, y_train.shape[0])).T\n",
        "\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning/pytorch/Happy_House/test_happy.h5', \"r\")\n",
        "    x_test = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    x_test = np.transpose(x_test, (0, 3, 1, 2))\n",
        "    y_test = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "    y_test = y_test.reshape((1, y_test.shape[0])).T\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "    X_train_tensor = torch.tensor(x_train, dtype=torch.float)/255\n",
        "    Y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "    X_test_tensor = torch.tensor(x_test, dtype=torch.float)/255\n",
        "    Y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset, train_loader, test_loader, classes"
      ],
      "metadata": {
        "id": "a31AHl68TJax"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LpqaUupYUdCO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}